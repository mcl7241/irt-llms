{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c473f903-f28b-4503-a5dd-4cc49ffbf9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset, concatenate_datasets\n",
    "from datasets.features import Value\n",
    "from transformers import (\n",
    "    BitsAndBytesConfig,\n",
    "    Gemma2ForSequenceClassification,\n",
    "    GemmaTokenizerFast,\n",
    "    Gemma2Config,\n",
    "    PreTrainedTokenizerBase, \n",
    "    EvalPrediction,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2771ca5-9578-40e0-98e8-93f07e7e6600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters here for training and lora config \n",
    "class Config:\n",
    "    output_dir: str = \"gemma-2-9b-train-tta-lora-mods-33k\"\n",
    "    checkpoint: str = \"unsloth/gemma-2-9b-it-bnb-4bit\" \n",
    "    max_length: int = 2048\n",
    "    n_splits: int = 5\n",
    "    fold_idx: int = 0\n",
    "    optim_type: str = \"adamw_8bit\"\n",
    "    per_device_train_batch_size: int = 2\n",
    "    gradient_accumulation_steps: int = 2  \n",
    "    per_device_eval_batch_size: int = 8\n",
    "    n_epochs: int = 1\n",
    "    freeze_layers: int = 0 # changed to 0 \n",
    "    lr: float = 2e-4 #  LR=2e-4 1 epoch linear schedule with warmup, then a=4 is best alpha for all rank. \n",
    "    warmup_steps: int = 20\n",
    "    lora_r: int = 64  # changed to 64, or 1024\n",
    "    lora_alpha: float = 4 # changed to 16, or 4 next \n",
    "    lora_dropout: float = 0.05\n",
    "    lora_bias: str = \"none\"\n",
    "    \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf605b7f-10a1-4cb4-8a4f-ca2c8451c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=config.lora_r,\n",
    "    lora_alpha=config.lora_alpha,\n",
    "    # only target self-attention\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"down_proj\",\"up_proj\",\"o_proj\",\"gate_proj\"], # added more target layers\n",
    "    layers_to_transform=[i for i in range(42) if i >= config.freeze_layers],\n",
    "    lora_dropout=config.lora_dropout,\n",
    "    bias=config.lora_bias,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1b4654b-c11f-41b7-890c-4f194e492453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate tokenizer and model \n",
    "tokenizer = GemmaTokenizerFast.from_pretrained(config.checkpoint)\n",
    "tokenizer.add_eos_token = True  # We'll add <eos> at the end\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60505e83-a93b-414b-acfd-6bc9c2efae31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at unsloth/gemma-2-9b-it-bnb-4bit and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Gemma2ForSequenceClassification(\n",
       "      (model): Gemma2Model(\n",
       "        (embed_tokens): Embedding(256000, 3584, padding_idx=0)\n",
       "        (layers): ModuleList(\n",
       "          (0-41): 42 x Gemma2DecoderLayer(\n",
       "            (self_attn): Gemma2Attention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=3584, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): Gemma2RotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Gemma2MLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=14336, out_features=3584, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=14336, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): PytorchGELUTanh()\n",
       "            )\n",
       "            (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "            (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "            (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "            (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=3584, out_features=3, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=3584, out_features=3, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    config.checkpoint,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4dff214-3228-43ba-9ffc-d2d851257dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 216,082,944 || all params: 9,457,799,680 || trainable%: 2.2847\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bc72ed6-0131-4baf-ad11-a05a4fa4cc6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Value(dtype='string', id=None),\n",
       " 'model_a': Value(dtype='string', id=None),\n",
       " 'model_b': Value(dtype='string', id=None),\n",
       " 'prompt': Value(dtype='string', id=None),\n",
       " 'response_a': Value(dtype='string', id=None),\n",
       " 'response_b': Value(dtype='string', id=None),\n",
       " 'winner_model_a': Value(dtype='int64', id=None),\n",
       " 'winner_model_b': Value(dtype='int64', id=None),\n",
       " 'winner_tie': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"lmsys/lmsys-arena-human-preference-55k\")\n",
    "current_features = dataset['train'].features\n",
    "current_features['id'] = Value('string')\n",
    "dataset['train'] = dataset['train'].cast(current_features)\n",
    "dataset['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39dd6419-d147-4ce2-a68d-5f7b50bfb4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Value(dtype='string', id=None),\n",
       " 'model_a': Value(dtype='string', id=None),\n",
       " 'model_b': Value(dtype='string', id=None),\n",
       " 'prompt': Value(dtype='string', id=None),\n",
       " 'response_a': Value(dtype='string', id=None),\n",
       " 'response_b': Value(dtype='string', id=None),\n",
       " 'winner_model_a': Value(dtype='int64', id=None),\n",
       " 'winner_model_b': Value(dtype='int64', id=None),\n",
       " 'winner_tie': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_33k = Dataset.from_csv(\"lmsys-33k-deduplicated.csv\")\n",
    "dataset_33k.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89d07596-9eff-4a7f-bf70-9490354edc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', 'winner_model_a', 'winner_model_b', 'winner_tie'],\n",
       "    num_rows: 78664\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = concatenate_datasets([dataset['train'], dataset_33k])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12bef1ac-b8b3-402c-bf7f-2b90b777ec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTokenizer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        tokenizer: PreTrainedTokenizerBase, \n",
    "        max_length: int\n",
    "    ) -> None:\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __call__(self, batch: dict) -> dict:\n",
    "        prompt = [\"<prompt>: \" + self.process_text(t) for t in batch[\"prompt\"]]\n",
    "        response_a = [\"\\n\\n<response_a of a gpt-4>: \" + self.process_text(t) for t in batch[\"response_a\"]]\n",
    "        response_b = [\"\\n\\n<response_b of a bird>: \" + self.process_text(t) for t in batch[\"response_b\"]]\n",
    "        texts = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
    "        tokenized = self.tokenizer(texts, max_length=self.max_length, truncation=True)\n",
    "        labels=[]\n",
    "        for a_win, b_win in zip(batch[\"winner_model_a\"], batch[\"winner_model_b\"]):\n",
    "            if a_win:\n",
    "                label = 0\n",
    "            elif b_win:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 2\n",
    "            labels.append(label)\n",
    "        return {**tokenized, \"labels\": labels}\n",
    "        \n",
    "    @staticmethod\n",
    "    def process_text(text: str) -> str:\n",
    "        return \" \".join(eval(text, {\"null\": \"\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb2dd990-2bf7-4cbc-9e8e-d92ae1a80ec4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "encode = CustomTokenizer(tokenizer, max_length=config.max_length)\n",
    "dataset = dataset.map(encode, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f83d0a2-4bde-4ac3-ac16-c8e47c7eccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds: EvalPrediction) -> dict:\n",
    "    preds = eval_preds.predictions\n",
    "    labels = eval_preds.label_ids\n",
    "    probs = torch.from_numpy(preds).float().softmax(-1).numpy()\n",
    "    loss = log_loss(y_true=labels, y_pred=probs)\n",
    "    acc = accuracy_score(y_true=labels, y_pred=preds.argmax(-1))\n",
    "    return {\"acc\": acc, \"log_loss\": loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8333d516-bc30-4530-8b81-b63e157d0f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of evaluation indices: 11496\n",
      "Number of training indices: 67168\n"
     ]
    }
   ],
   "source": [
    "eval_idx = [i for i in range(57477) if i % 5 == 0]  # Get every 5th index\n",
    "train_idx = [i for i in range(len(dataset)) if i not in eval_idx]\n",
    "\n",
    "# If you want to print the lengths of the arrays to verify\n",
    "print(f\"Number of evaluation indices: {len(eval_idx)}\")\n",
    "print(f\"Number of training indices: {len(train_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53a2bbf7-5cc3-49da-be84-74054e65ea44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[2, 235322, 39038, 78880, 2125, 665, 89397, 18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>292873</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>[\"Construct a rap battle, in the style of Epic...</td>\n",
       "      <td>[\"[Zeus]\\nYo, it's the king of the gods on the...</td>\n",
       "      <td>[\"(Verse 1 - Zeus)\\n\\nI'm the king of the gods...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[2, 235322, 39038, 78880, 58863, 476, 13483, 9...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>497862</td>\n",
       "      <td>vicuna-7b</td>\n",
       "      <td>guanaco-33b</td>\n",
       "      <td>[\"write a python function to upload all the fi...</td>\n",
       "      <td>[\"Sure, here's a Python function that uses the...</td>\n",
       "      <td>[\"Sure, here's an example function in Python t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[2, 235322, 39038, 78880, 5598, 476, 17706, 14...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>863398</td>\n",
       "      <td>llama2-70b-steerlm-chat</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>[\"what do you know about real estate\"]</td>\n",
       "      <td>[\"Real estate refers to the land and buildings...</td>\n",
       "      <td>[\"1. **Types of Real Estate:**\\n    * **Reside...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[2, 235322, 39038, 78880, 1212, 749, 692, 1230...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1256092</td>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[\"Write a python code that calculates sum of 5...</td>\n",
       "      <td>[\"Here is the python code that calculates the ...</td>\n",
       "      <td>[\"Here is a Python code that calculates the su...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[2, 235322, 39038, 78880, 15615, 476, 17706, 3...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                  model_a             model_b  \\\n",
       "0    30192       gpt-4-1106-preview          gpt-4-0613   \n",
       "1   292873               vicuna-13b          gpt-4-0314   \n",
       "2   497862                vicuna-7b         guanaco-33b   \n",
       "3   863398  llama2-70b-steerlm-chat  gemini-pro-dev-api   \n",
       "4  1256092               claude-2.1          vicuna-13b   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  [\"Is it morally right to try to have a certain...   \n",
       "1  [\"Construct a rap battle, in the style of Epic...   \n",
       "2  [\"write a python function to upload all the fi...   \n",
       "3             [\"what do you know about real estate\"]   \n",
       "4  [\"Write a python code that calculates sum of 5...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  [\"The question of whether it is morally right ...   \n",
       "1  [\"[Zeus]\\nYo, it's the king of the gods on the...   \n",
       "2  [\"Sure, here's a Python function that uses the...   \n",
       "3  [\"Real estate refers to the land and buildings...   \n",
       "4  [\"Here is the python code that calculates the ...   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "0  [\"As an AI, I don't have personal beliefs or o...               1   \n",
       "1  [\"(Verse 1 - Zeus)\\n\\nI'm the king of the gods...               0   \n",
       "2  [\"Sure, here's an example function in Python t...               0   \n",
       "3  [\"1. **Types of Real Estate:**\\n    * **Reside...               0   \n",
       "4  [\"Here is a Python code that calculates the su...               0   \n",
       "\n",
       "   winner_model_b  winner_tie  \\\n",
       "0               0           0   \n",
       "1               1           0   \n",
       "2               1           0   \n",
       "3               1           0   \n",
       "4               0           1   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [2, 235322, 39038, 78880, 2125, 665, 89397, 18...   \n",
       "1  [2, 235322, 39038, 78880, 58863, 476, 13483, 9...   \n",
       "2  [2, 235322, 39038, 78880, 5598, 476, 17706, 14...   \n",
       "3  [2, 235322, 39038, 78880, 1212, 749, 692, 1230...   \n",
       "4  [2, 235322, 39038, 78880, 15615, 476, 17706, 3...   \n",
       "\n",
       "                                      attention_mask  labels  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       1  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       1  \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       1  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset=dataset.select(eval_idx)\n",
    "eval_dataframe = eval_dataset.to_pandas()\n",
    "eval_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02d17b33-a0e0-43d0-9925-0994f939fbb9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = dataset.select(train_idx)\n",
    "eval_dataset = dataset.select(eval_idx)\n",
    "\n",
    "train_batch_size = training_args.per_device_train_batch_size\n",
    "eval_batch_size = training_args.per_device_eval_batch_size\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=train_batch_size, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    eval_dataset, \n",
    "    batch_size=eval_batch_size, \n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a826d68-fda2-4eec-a78c-e16b7e6d679a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "each element in list of batch should be of equal size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m total_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Loop through batches\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:316\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    256\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:154\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMutableMapping):\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;66;03m# The mapping type may have extra properties, so we can't just\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# use `type(data)(...)` to create the new mapping.\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# Create a clone and update it if the mapping type is mutable.\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     clone \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(elem)\n\u001b[0;32m--> 154\u001b[0m     clone\u001b[38;5;241m.\u001b[39mupdate({key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clone\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:169\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    167\u001b[0m elem_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mnext\u001b[39m(it))\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(elem) \u001b[38;5;241m==\u001b[39m elem_size \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m it):\n\u001b[0;32m--> 169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meach element in list of batch should be of equal size\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    170\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: each element in list of batch should be of equal size"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import AdamW\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model define above \n",
    "\n",
    "# Send the model to device (GPU or CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=config.lr)\n",
    "writer = SummaryWriter(training_args.logging_dir)\n",
    "\n",
    "# Training loop\n",
    "best_accuracy = 0.0\n",
    "global_step = 0\n",
    "\n",
    "for epoch in range(training_args.num_train_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Loop through batches\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Backpropagation with gradient accumulation\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization step every `gradient_accumulation_steps`\n",
    "        if (step + 1) % training_args.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        correct_preds += (preds == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        # Log progress to TensorBoard every `logging_steps`\n",
    "        if global_step % training_args.logging_steps == 0:\n",
    "            writer.add_scalar(\"Loss/Train\", loss.item(), global_step)\n",
    "            writer.add_scalar(\"Accuracy/Train\", correct_preds / total_samples, global_step)\n",
    "\n",
    "        global_step += 1\n",
    "\n",
    "    # Validation step after each epoch\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct_preds = 0\n",
    "    val_total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for val_batch in val_loader:\n",
    "            input_ids = val_batch['input_ids'].to(device)\n",
    "            attention_mask = val_batch['attention_mask'].to(device)\n",
    "            labels = val_batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            val_loss += outputs.loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs.logits, dim=-1)\n",
    "            val_correct_preds += (preds == labels).sum().item()\n",
    "            val_total_samples += labels.size(0)\n",
    "\n",
    "    val_accuracy = val_correct_preds / val_total_samples\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    # Log validation results\n",
    "    writer.add_scalar(\"Loss/Validation\", val_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/Validation\", val_accuracy, epoch)\n",
    "\n",
    "    # Print progress\n",
    "    print(f'Epoch [{epoch+1}/{training_args.num_train_epochs}], Loss: {running_loss/len(train_loader)}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}')\n",
    "\n",
    "    # Save best model if accuracy improves\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        model_save_path = os.path.join(training_args.output_dir, f'best_model_epoch_{epoch+1}_val_acc_{best_accuracy:.4f}.pth')\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "# Save the final model and close the tensorboard writer\n",
    "torch.save(model.state_dict(), os.path.join(training_args.output_dir, 'final_model.pth'))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b21d326-8eec-47ab-9b7f-5405b223df5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    overwrite_output_dir=True,\n",
    "    report_to=\"tensorboard\",  # Enable reporting to TensorBoard\n",
    "    num_train_epochs=config.n_epochs,\n",
    "    per_device_train_batch_size=config.per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "    per_device_eval_batch_size=config.per_device_eval_batch_size,\n",
    "    logging_steps=10,  # Log every 10 steps\n",
    "    logging_dir='./logs/gemma-2-9b-train-tta-lora-mods-33k-2048-random-words',  # Directory for TensorBoard logs\n",
    "    eval_strategy=\"steps\",  # Evaluate every specific number of steps\n",
    "    eval_steps=5000,  # Evaluate every 2000 steps\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=5000,\n",
    "    metric_for_best_model=\"eval_acc\",  # Save based on eval accuracy\n",
    "    optim=config.optim_type,\n",
    "    fp16=True,\n",
    "    learning_rate=config.lr,\n",
    "    warmup_steps=config.warmup_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1046d186-032b-4f2b-98ba-9ec2cf3ac782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_214493/2740791879.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
      ":DefaultFlowCallback\n",
      "TensorBoardCallback\n",
      "/home/skunk/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      2\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args, \n\u001b[1;32m      3\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[TensorBoardCallback()],\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/trainer.py:2122\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2120\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2123\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/trainer.py:2474\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2471\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2473\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2474\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2477\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2478\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2479\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2480\u001b[0m ):\n\u001b[1;32m   2481\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2482\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/trainer.py:3572\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3571\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3572\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3574\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3576\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3577\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3578\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/trainer.py:3625\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3623\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3624\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3625\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3626\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/accelerate/utils/operations.py:820\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/accelerate/utils/operations.py:808\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/amp/autocast_mode.py:16\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/peft/peft_model.py:1303\u001b[0m, in \u001b[0;36mPeftModelForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m peft_config\u001b[38;5;241m.\u001b[39mpeft_type \u001b[38;5;241m==\u001b[39m PeftType\u001b[38;5;241m.\u001b[39mPOLY:\n\u001b[1;32m   1302\u001b[0m             kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m task_ids\n\u001b[0;32m-> 1303\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1314\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:179\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/models/gemma2/modeling_gemma2.py:1254\u001b[0m, in \u001b[0;36mGemma2ForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1252\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1254\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpooled_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1257\u001b[0m     output \u001b[38;5;241m=\u001b[39m (pooled_logits,) \u001b[38;5;241m+\u001b[39m transformer_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/loss/loss_utils.py:67\u001b[0m, in \u001b[0;36mForSequenceClassificationLoss\u001b[0;34m(labels, pooled_logits, config, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m         loss \u001b[38;5;241m=\u001b[39m loss_fct(pooled_logits, labels)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 67\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mfixed_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpooled_logits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     69\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m BCEWithLogitsLoss()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/loss/loss_utils.py:26\u001b[0m, in \u001b[0;36mfixed_cross_entropy\u001b[0;34m(source, target, num_items_in_batch, ignore_index, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfixed_cross_entropy\u001b[39m(source, target, num_items_in_batch: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, ignore_index: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     25\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_items_in_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 26\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reduction \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     28\u001b[0m         loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m num_items_in_batch\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/functional.py:3086\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3085\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    args=training_args, \n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset.select(train_idx),\n",
    "    eval_dataset=dataset.select(eval_idx),\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    callbacks=[TensorBoardCallback()],\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bf2ab6-27ec-4fdf-ac8f-80b81ce787ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='254' max='1437' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 254/1437 21:45 < 1:41:42, 0.19 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_dataset=dataset.select(eval_idx)\n",
    "predictions = trainer.predict(eval_dataset)\n",
    "pred_labels = np.argmax(predictions.predictions, axis=1)  # Get the predicted class (3-way classification)\n",
    "true_labels = predictions.label_ids  # Get the true class labels\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(true_labels, pred_labels, labels=[0, 1, 2])\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Model A Win', 'Model B Win', 'Tie'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix for 3-Way Model Classification')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dacd9c4-d246-4140-8a96-6b15ab9feb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(true_labels, pred_labels, labels=[0, 1, 2])\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Model A Win', 'Model B Win', 'Tie'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix for 3-Way Model Classification')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d95fd0-f5be-41ee-bd6f-a50af05f0369",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
